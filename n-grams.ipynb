{"cells":[{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import re\n","import csv\n","import string\n","import operator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","#nltk.download('all')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from collections import Counter"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Auxiliar functions\n","- remove_scenes_actions\n","- extract_trigrams\n","- generate_ngrams"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def remove_scenes_actions(line):\n","    new = \"\"\n","    found = False\n","    for letter in line:\n","        if letter == \"(\" or letter ==\"[\":\n","            found = True\n","        if letter == \")\" or letter ==\"]\":\n","            found = False\n","\n","        #outside brackets\n","        if found == False and letter!=\")\" and letter!=\"]\":\n","            new = new + letter\n","\n","    \n","    return(new)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def extract_trigrams(sentence):\n","    # Step 1\n","    words_list = sentence.split(\" \")\n","\n","    # Step 2\n","    trigrams_list = []\n","\n","    # Step 3\n","    for i in range(0 , len(words_list) - 2):\n","        if words_list[i]!='' and words_list[i+1]!='' and words_list[i+2]!='':\n","            trigram = [words_list[i],words_list[i+1],words_list[i + 2]]\n","            trigrams_list.append(trigram)\n","    return trigrams_list"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def generate_ngrams(sentence: str, n: int):\n","    # Convert sentence to lowercase and remove punctuation\n","    import string\n","    sentence = sentence.lower().translate(str.maketrans('', '', string.punctuation))\n","\n","    # Split sentence into words\n","    words = sentence.split()\n","\n","    # Generate N-grams\n","    ngrams = []\n","    for i in range(len(words) - n + 1):\n","        ngrams.append(' '.join(words[i:i+n]))\n","\n","    return ngrams"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["file = open(\"friends.csv\", 'r', encoding=\"utf8\")\n","csvreader = csv.reader(file)\n","data = list(csvreader)\n","\n","characters =[\"Rachel\", \"Monica\", \"Joey\", \"Chandler\", \"Ross\", \"Phoebe\"]\n","\n","stop_words = set(stopwords.words('english'))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["UNIGRAMS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for character in characters:\n","        lines = []\n","        sp_character = []\n","        for row in data:\n","            if row[-2] == character:\n","                #we only want dialogue\n","                str = remove_scenes_actions(row[-1])\n","                lines.append(str)\n","\n","        #create auxiliar vector WITHOUT punctuation for TF-IDF purposes\n","        words = []\n","\n","        for line in lines:\n","            #remve punctuation\n","            line = line.translate(str.maketrans('', '', string.punctuation))\n","            #sp_character.append(line)\n","            \n","            line = word_tokenize(line)\n","\n","            for word in line:\n","                words.append(word.lower())\n","\n","        counts = Counter(words)\n","        counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n","        print(character)\n","\n","        for elem in counts:\n","            if elem[0] not in stop_words:\n","                print(elem)\n","        print(\"***************************************\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["TRIGRAMS "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for character in characters:\n","        lines = []\n","\n","        for row in data:\n","            if row[-2] == character:\n","                #we only want dialogue\n","                str = remove_scenes_actions(row[-1])\n","                lines.append(str)\n","\n","        trigrams = []\n","\n","        for line in lines:\n","            #remve punctuation\n","            line = line.translate(str.maketrans('', '', string.punctuation))\n","\n","            trigram = generate_ngrams(line,3)\n","            for word in trigram:\n","                trigrams.append(word)\n","\n","        counter = {}\n","        for elem in trigrams:\n","            if elem in counter:\n","                 counter[elem]+=1\n","            else:\n","                 counter[elem]=1\n","\n","        \n","        counter_sorted = sorted(counter.items(), key=operator.itemgetter(1))\n","\n","        #counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n","        print(character)\n","\n","        print(\"***************************************\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":2}
