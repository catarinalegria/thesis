{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "characters = ['Monica Geller', 'Joey Tribbiani', 'Chandler Bing', 'Phoebe Buffay', 'Ross Geller', 'Rachel Green', 'others']\n",
    "\n",
    "#characters = ['Monica Geller', 'Joey Tribbiani', 'Chandler Bing', 'Phoebe Buffay', 'Ross Geller', 'Rachel Green']\n",
    "\n",
    "\n",
    "#test set 1 = season 8\n",
    "\n",
    "with open('sets/test_set1.json') as f:\n",
    "    test_set1 = json.load(f)\n",
    "\n",
    "with open('sets/train_set1.json') as f:\n",
    "    train_set1 = json.load(f)\n",
    "\n",
    "################################################################\n",
    "\n",
    "#test set 2 = 10% of each season\n",
    "\n",
    "with open('sets/test_set2.json') as f:\n",
    "    test_set2 = json.load(f)\n",
    "\n",
    "with open('sets/train_set2.json') as f:\n",
    "    train_set2 = json.load(f)\n",
    "\n",
    "\n",
    "#CHANGE HERE\n",
    "test_set = test_set2\n",
    "train_set = train_set2\n",
    "#number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(vector):\n",
    "\n",
    "    angles = {}\n",
    "\n",
    "    for character in characters:\n",
    "        angles[character] = cosine_similarity(vector.reshape(1,-1), embeddings[character].reshape(1,-1))[0][0]\n",
    "\n",
    "    \n",
    "    \n",
    "    #Smaller angles between vectors produce larger cosine values, indicating greater cosine similarity\n",
    "\n",
    "    character = [i for i in angles if angles[i]==max(angles.values())]\n",
    "\n",
    "\n",
    "    return character[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size embedding 2000\n",
      "16.557484441532917\n",
      "accuracy:  21.274156567310843\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#change x for number of lines \n",
    "#values = [5,10,20,50,100,150,200,500,1000,2000,5000]\n",
    "values = [2000]\n",
    "\n",
    "for value in values:\n",
    "    sentences = []\n",
    "\n",
    "    for character in characters:\n",
    "        f = open(\"embeddings\" + \"/\" + character + str(value) + \".txt\", \"r\")\n",
    "        lines = f.readlines()\n",
    "        sentences.append(lines)\n",
    "\n",
    "    i=0\n",
    "    embeddings = {}\n",
    "    for character in characters:\n",
    "        embeddings[character] = model.encode(sentences[i])\n",
    "        i+=1\n",
    "\n",
    "    #to confirm number of lines used to create the embedding\n",
    "    print(\"size embedding\", len(embeddings['Monica Geller']))\n",
    "\n",
    "    for character in characters:\n",
    "\n",
    "        mean = embeddings[character][0]\n",
    "        for embedding in embeddings[character]:\n",
    "            mean += embedding\n",
    "        \n",
    "        embeddings[character] = mean\n",
    "    \n",
    "\n",
    "    #####test set computation\n",
    "    \n",
    "    predicted = []\n",
    "    real = []\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for utterance in test_set:\n",
    "        if len(utterance['speakers']) == 1:\n",
    "\n",
    "            total += 1\n",
    "\n",
    "            line_embed = model.encode(utterance['transcript'])\n",
    "        \n",
    "            pred = compute_similarity(line_embed)\n",
    "\n",
    "            predicted.append(pred)\n",
    "            real.append(utterance['speakers'][0])\n",
    "\n",
    "            if pred == utterance['speakers'][0]:\n",
    "                correct+=1\n",
    "            elif pred == \"others\" and utterance['speakers'][0] not in ['Monica Geller', 'Joey Tribbiani', 'Chandler Bing', 'Phoebe Buffay', 'Ross Geller', 'Rachel Green']:\n",
    "                correct+=1\n",
    "\n",
    "                        \n",
    "    print(accuracy_score(real, predicted)*100)\n",
    "\n",
    "    accuracy = (float(correct)/total)*100\n",
    "\n",
    "    print(\"accuracy: \", accuracy)\n",
    "\n",
    "    #print(\"f1 score: \", f1_score(real, predicted, average='macro'))\n",
    "\n",
    "    print(len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = []\n",
    "speakers = []\n",
    "\n",
    "\n",
    "for utterance in test_set:\n",
    "    if utterance['speakers'] != []:\n",
    "        all_lines.append(utterance['transcript'])\n",
    "\n",
    "for utterance in test_set:\n",
    "    if utterance['speakers'] != []:\n",
    "        speakers.append(utterance['speakers'][0])\n",
    "\n",
    "#remove duplicates\n",
    "#all_lines = list( dict.fromkeys(all_lines) )\n",
    "\n",
    "\n",
    "tf_idf = tf_idf_calculator(all_lines)\n",
    "\n",
    "all_lines_tf_idf = []\n",
    "\n",
    "#format: all_lines_tf_idf = [...,[tf-idf score ,sentence],...]\n",
    "for i,sentence in enumerate(all_lines):\n",
    "    cell = []\n",
    "    cell= [tf_idf[i], sentence, speakers[i]]\n",
    "    all_lines_tf_idf.append(cell)\n",
    "    \n",
    "# lower -> higher     \n",
    "sorted_list = sorted(all_lines_tf_idf)\n",
    "\n",
    "tf_idfs_utterances = []\n",
    "\n",
    "#get only the strings\n",
    "for elem in sorted_list:\n",
    "    tf_idfs_utterances.append(elem[1])\n",
    "\n",
    "\n",
    "for elem in sorted_list:\n",
    "    print(elem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(vector):\n",
    "\n",
    "    angles = {}\n",
    "\n",
    "    for character in characters:\n",
    "        angles[character] = cosine_similarity(vector.reshape(1,-1), embeddings[character].reshape(1,-1))[0][0]\n",
    "\n",
    "    \n",
    "    \n",
    "    #Smaller angles between vectors produce larger cosine values, indicating greater cosine similarity\n",
    "\n",
    "    character = [i for i in angles if angles[i]==max(angles.values())]\n",
    "\n",
    "\n",
    "    return character[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.067147068457254\n",
      "accuracy:  19.84932852931543\n",
      "f1 score:  0.0034750003354247954\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "real = []\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for utterance in test_set:\n",
    "    if len(utterance['speakers']) == 1:\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        line_embed = model.encode(utterance['transcript'])\n",
    "    \n",
    "        pred = compute_similarity(line_embed)\n",
    "\n",
    "        predicted.append(pred)\n",
    "        real.append(utterance['speakers'][0])\n",
    "\n",
    "        if pred == utterance['speakers'][0]:\n",
    "            correct+=1\n",
    "        elif pred == \"others\" and utterance['speakers'][0] not in ['Monica Geller', 'Joey Tribbiani', 'Chandler Bing', 'Phoebe Buffay', 'Ross Geller', 'Rachel Green']:\n",
    "            correct+=1\n",
    "\n",
    "                    \n",
    "print(accuracy_score(real, predicted)*100)\n",
    "\n",
    "accuracy = (float(correct)/total)*100\n",
    "\n",
    "print(\"accuracy: \", accuracy)\n",
    "\n",
    "print(\"f1 score: \", f1_score(real, predicted, average='macro'))\n",
    "\n",
    "print(len(characters))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier WITH filter in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.319952067106051\n",
      "18.184541641701617\n",
      "7\n",
      "30\n",
      "46.25664144260183\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "real = []\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "#threshold = 80\n",
    "threshold = 30\n",
    "\n",
    "all = 0\n",
    "for utterance in test_set:\n",
    "    if len(utterance['speakers']) == 1:\n",
    "        all += 1\n",
    "\n",
    "        index = tf_idfs_utterances.index(utterance['transcript'])\n",
    "\n",
    "        #if sorted_list[index][0] <= threshold:\n",
    "        if sorted_list[index][0] >= threshold:\n",
    "\n",
    "            total += 1\n",
    "\n",
    "            line_embed = model.encode(utterance['transcript'])\n",
    "        \n",
    "            pred = compute_similarity(line_embed)\n",
    "\n",
    "            predicted.append(pred)\n",
    "            real.append(utterance['speakers'][0])\n",
    "\n",
    "            if pred == utterance['speakers'][0]:\n",
    "                correct+=1\n",
    "            elif pred == \"others\" and utterance['speakers'][0] not in ['Monica Geller', 'Joey Tribbiani', 'Chandler Bing', 'Phoebe Buffay', 'Ross Geller', 'Rachel Green']:\n",
    "                correct+=1\n",
    "\n",
    "\n",
    "                    \n",
    "print(accuracy_score(real, predicted)*100)\n",
    "\n",
    "accuracy = (float(correct)/total)*100\n",
    "\n",
    "print(accuracy)\n",
    "print(len(characters))\n",
    "print(threshold)\n",
    "\n",
    "print(100 - float(total/all)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
