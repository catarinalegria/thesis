{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = []\n",
    "\n",
    "for i in range(1,11):\n",
    "\n",
    "    # load season i\n",
    "    if i<10:\n",
    "        json_file = 'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_0'+str(i)+'.json'\n",
    "    else:\n",
    "        json_file = 'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_10.json'\n",
    "    \n",
    "    r = requests.get(json_file)\n",
    "    \n",
    "    seasons.append(json.loads(r.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes:  236\n",
      "Number of scenes:  3107\n",
      "Number of utterances:  61310\n",
      "Number of speakers:  701\n",
      "Average number of tokens per utterance:  10.159745555374327\n",
      "Average number of utterances per scene:  19.732861280978437\n"
     ]
    }
   ],
   "source": [
    "#for statistical purposes\n",
    "\n",
    "utterances = []\n",
    "episodes = []\n",
    "scenes = []\n",
    "speakers = []\n",
    "\n",
    "utterances_lines = []\n",
    "\n",
    "\n",
    "for season in seasons:\n",
    "    for episode in season['episodes']:\n",
    "        episodes.append(episode['episode_id'])\n",
    "        for scene in episode['scenes']:\n",
    "            scenes.append(scene['scene_id'])\n",
    "            for utterance in scene['utterances']:\n",
    "                #dont want non-speech\n",
    "                if utterance['transcript'] != \"\":\n",
    "                    utterances.append(utterance['utterance_id'])\n",
    "                    utterances_lines.append(utterance['transcript'])\n",
    "                    for speaker in utterance['speakers']:\n",
    "                        if speaker not in speakers:\n",
    "                            speakers.append(utterance['speakers'][0])\n",
    "\n",
    "print(\"Number of episodes: \", len(episodes))\n",
    "print(\"Number of scenes: \", len(scenes))\n",
    "print(\"Number of utterances: \", len(utterances))\n",
    "print(\"Number of speakers: \", len(speakers))\n",
    "print(\"Average number of tokens per utterance: \", sum([len(utterance.split()) for utterance in utterances_lines])/len(utterances_lines))\n",
    "print(\"Average number of utterances per scene: \", len(utterances)/len(scenes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set 1: season 8\n",
    "#train set 2: first 7 seasons\n",
    "\n",
    "test_set = []\n",
    "\n",
    "for episode in seasons[7]['episodes']:\n",
    "    for scene in episode['scenes']:\n",
    "        for utterance in scene['utterances']:\n",
    "            if utterance['speakers'] != []:\n",
    "                test_set.append(utterance)\n",
    "\n",
    "\n",
    "train_set = []\n",
    "\n",
    "for season in seasons:\n",
    "    if season['season_id'] in ['s01', 's02', 's03', 's04', 's05', 's06', 's07']:\n",
    "        for episode in season['episodes']:\n",
    "            for scene in episode['scenes']:\n",
    "                for utterance in scene['utterances']:\n",
    "                    if utterance['speakers'] != [] and utterance not in test_set:\n",
    "                        train_set.append(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes:  194\n",
      "Number of scenes:  2579\n",
      "Number of utterances:  49740\n",
      "Number of speakers:  596\n",
      "Average number of tokens per utterance:  10.07227583433856\n",
      "Average number of utterances per scene:  19.2865451725475\n",
      "Monica:  0.13772106109324758\n",
      "Chandler:  0.13818327974276529\n",
      "Ross:  0.14887459807073955\n",
      "Joey:  0.132516077170418\n",
      "Phoebe:  0.12067926045016077\n",
      "Rachel:  0.1534967845659164\n",
      "Others:  0.1685289389067524\n"
     ]
    }
   ],
   "source": [
    "utterances = []\n",
    "episodes = []\n",
    "scenes = []\n",
    "speakers = []\n",
    "\n",
    "utterances_lines = []\n",
    "\n",
    "set1 = test_set + train_set\n",
    "\n",
    "for utterance in set1:\n",
    "    if utterance['transcript'] != \"\":\n",
    "        utterances.append(utterance['utterance_id'])\n",
    "        utterances_lines.append(utterance['transcript'])\n",
    "\n",
    "        #regex to remove episode from utterance id\n",
    "        episode = utterance['utterance_id'][0:7]\n",
    "        scene = utterance['utterance_id'][0:11]\n",
    "\n",
    "        if episode not in episodes:\n",
    "            episodes.append(episode)\n",
    "\n",
    "        if scene not in scenes:\n",
    "            scenes.append(scene)\n",
    "\n",
    "        for speaker in utterance['speakers']:\n",
    "            if speaker not in speakers:\n",
    "                speakers.append(utterance['speakers'][0])\n",
    "\n",
    "print(\"Number of episodes: \", len(episodes))\n",
    "print(\"Number of scenes: \", len(scenes))\n",
    "print(\"Number of utterances: \", len(utterances))\n",
    "print(\"Number of speakers: \", len(speakers))\n",
    "print(\"Average number of tokens per utterance: \", sum([len(utterance.split()) for utterance in utterances_lines])/len(utterances_lines))\n",
    "print(\"Average number of utterances per scene: \", len(utterances)/len(scenes))\n",
    "\n",
    "\n",
    "#lets count utterances per speaker\n",
    "monica = []\n",
    "chandler = []\n",
    "ross = []\n",
    "joey = []\n",
    "phoebe = []\n",
    "rachel = []\n",
    "others = []\n",
    "\n",
    "\n",
    "\n",
    "for utterance in set1:\n",
    "    if utterance['speakers'] == ['Monica Geller']:\n",
    "        monica.append(utterance)\n",
    "    elif utterance['speakers'] == ['Chandler Bing']:\n",
    "        chandler.append(utterance)\n",
    "    elif utterance['speakers'] == ['Ross Geller']:\n",
    "        ross.append(utterance)\n",
    "    elif utterance['speakers'] == ['Joey Tribbiani']:\n",
    "        joey.append(utterance)\n",
    "    elif utterance['speakers'] == ['Phoebe Buffay']:\n",
    "        phoebe.append(utterance)\n",
    "    elif utterance['speakers'] == ['Rachel Green']:\n",
    "        rachel.append(utterance)\n",
    "    else:\n",
    "        others.append(utterance)\n",
    "\n",
    "#lets get the percentages of each speaker\n",
    "print(\"Monica: \", len(monica)/len(set1))\n",
    "print(\"Chandler: \", len(chandler)/len(set1))\n",
    "print(\"Ross: \", len(ross)/len(set1))\n",
    "print(\"Joey: \", len(joey)/len(set1))\n",
    "print(\"Phoebe: \", len(phoebe)/len(set1))\n",
    "print(\"Rachel: \", len(rachel)/len(set1))\n",
    "print(\"Others: \", len(others)/len(set1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sets/test_set1.json\", \"w\") as outfile:\n",
    "    json.dump(test_set, outfile)\n",
    "\n",
    "\n",
    "with open(\"sets/train_set1.json\", \"w\") as outfile:\n",
    "    json.dump(train_set, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set 2: 10% of utterances from each season\n",
    "\n",
    "all_seasons = []\n",
    "for season in seasons:\n",
    "    utterances = []\n",
    "    selection = []\n",
    "    for episode in season['episodes']:\n",
    "        for scene in episode['scenes']:\n",
    "            for utterance in scene['utterances']:\n",
    "                if utterance['speakers'] != []:\n",
    "                    utterances.append(utterance)\n",
    "\n",
    "    num_elements = len(utterances)\n",
    "    num_elements_to_extract = int(num_elements * 0.1)  # Calculate 10% of the total elements\n",
    "    selection = random.sample(utterances, num_elements_to_extract)\n",
    "\n",
    "    all_seasons.append(selection)\n",
    "\n",
    "\n",
    "test_set = []\n",
    "for season in all_seasons:\n",
    "    for utterance in season:\n",
    "        test_set.append(utterance)\n",
    "\n",
    "train_set = []\n",
    "for season in seasons:\n",
    "    for episode in season['episodes']:\n",
    "        for scene in episode['scenes']:\n",
    "            for utterance in scene['utterances']:\n",
    "                if utterance['speakers'] != [] and utterance not in test_set:\n",
    "                    train_set.append(utterance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of episodes:  236\n",
      "Number of scenes:  3099\n",
      "Number of utterances:  61308\n",
      "Number of speakers:  701\n",
      "Average number of tokens per utterance:  10.159881255301103\n",
      "Average number of utterances per scene:  19.783155856727976\n",
      "Monica:  0.13763083243666244\n",
      "Chandler:  0.13800580390622452\n",
      "Ross:  0.1493038573152043\n",
      "Joey:  0.13331050898301217\n",
      "Phoebe:  0.12233851772147772\n",
      "Rachel:  0.1518634451726499\n",
      "Others:  0.16754703446476898\n"
     ]
    }
   ],
   "source": [
    "utterances = []\n",
    "episodes = []\n",
    "scenes = []\n",
    "speakers = []\n",
    "\n",
    "utterances_lines = []\n",
    "\n",
    "set2 = test_set + train_set\n",
    "\n",
    "for utterance in set2:\n",
    "    if utterance['transcript'] != \"\":\n",
    "        utterances.append(utterance['utterance_id'])\n",
    "        utterances_lines.append(utterance['transcript'])\n",
    "\n",
    "        #regex to remove episode from utterance id\n",
    "        episode = utterance['utterance_id'][0:7]\n",
    "        scene = utterance['utterance_id'][0:11]\n",
    "\n",
    "        if episode not in episodes:\n",
    "            episodes.append(episode)\n",
    "\n",
    "        if scene not in scenes:\n",
    "            scenes.append(scene)\n",
    "\n",
    "        for speaker in utterance['speakers']:\n",
    "            if speaker not in speakers:\n",
    "                speakers.append(utterance['speakers'][0])\n",
    "\n",
    "print(\"Number of episodes: \", len(episodes))\n",
    "print(\"Number of scenes: \", len(scenes))\n",
    "print(\"Number of utterances: \", len(utterances))\n",
    "print(\"Number of speakers: \", len(speakers))\n",
    "print(\"Average number of tokens per utterance: \", sum([len(utterance.split()) for utterance in utterances_lines])/len(utterances_lines))\n",
    "print(\"Average number of utterances per scene: \", len(utterances)/len(scenes))\n",
    "\n",
    "\n",
    "monica = []\n",
    "chandler = []\n",
    "ross = []\n",
    "joey = []\n",
    "phoebe = []\n",
    "rachel = []\n",
    "others = []\n",
    "\n",
    "for utterance in set2:\n",
    "    if utterance['speakers'] == ['Monica Geller']:\n",
    "        monica.append(utterance)\n",
    "    elif utterance['speakers'] == ['Chandler Bing']:\n",
    "        chandler.append(utterance)\n",
    "    elif utterance['speakers'] == ['Ross Geller']:\n",
    "        ross.append(utterance)\n",
    "    elif utterance['speakers'] == ['Joey Tribbiani']:\n",
    "        joey.append(utterance)\n",
    "    elif utterance['speakers'] == ['Phoebe Buffay']:\n",
    "        phoebe.append(utterance)\n",
    "    elif utterance['speakers'] == ['Rachel Green']:\n",
    "        rachel.append(utterance)\n",
    "    else:\n",
    "        others.append(utterance)\n",
    "\n",
    "#lets get the percentages of each speaker\n",
    "print(\"Monica: \", len(monica)/len(set2))\n",
    "print(\"Chandler: \", len(chandler)/len(set2))\n",
    "print(\"Ross: \", len(ross)/len(set2))\n",
    "print(\"Joey: \", len(joey)/len(set2))\n",
    "print(\"Phoebe: \", len(phoebe)/len(set2))\n",
    "print(\"Rachel: \", len(rachel)/len(set2))\n",
    "print(\"Others: \", len(others)/len(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sets/test_set2.json\", \"w\") as outfile:\n",
    "    json.dump(test_set, outfile)\n",
    "\n",
    "\n",
    "with open(\"sets/train_set2.json\", \"w\") as outfile:\n",
    "    json.dump(train_set, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nkproj",
   "language": "python",
   "name": "nkproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
