{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /cfs/home/u021320/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import string\n",
    "import math\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = ['Monica Geller', 'Joey Tribbiani', 'Chandler Bing', 'Phoebe Buffay', 'Ross Geller', 'Rachel Green', 'others']\n",
    "\n",
    "#test set 1 = season 8\n",
    "\n",
    "with open('sets/train_set1.json') as f:\n",
    "    train_set1 = json.load(f)\n",
    "\n",
    "with open('sets/train_set2.json') as f:\n",
    "    train_set2 = json.load(f)\n",
    "\n",
    "#CHANGE HERE\n",
    "train_set = train_set1\n",
    "#number = 1\n",
    "\n",
    "all_lines = []\n",
    "\n",
    "#corpus\n",
    "for line in train_set:\n",
    "    all_lines.append(line['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit(all_lines)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "#tf-idf for each character\n",
    "for character in characters:\n",
    "    character_lines = []\n",
    "    for line in train_set:\n",
    "        if character != 'others' and character in line['speakers']:\n",
    "            character_lines.append(line['transcript'])\n",
    "        elif character == 'others' and line['speakers'][0] not in characters:\n",
    "            character_lines.append(line['transcript'])\n",
    "\n",
    "\n",
    "    tf_idf = vectorizer.transform(character_lines)\n",
    "\n",
    "    dense = tf_idf.todense()\n",
    "    denselist = dense.tolist()\n",
    "    df = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for sentence in dense:\n",
    "        values.append(sentence.sum())\n",
    "\n",
    "    \n",
    "    #associate values with sentences\n",
    "    sentences = []\n",
    "    for i in range(len(character_lines)):\n",
    "        sentences.append({'sentence': character_lines[i], 'value': values[i]})\n",
    "    \n",
    "    #sort sentences by value\n",
    "    sentences = sorted(sentences, key = lambda i: i['value'], reverse=True)\n",
    "\n",
    "    #change x for number of lines \n",
    "    values = [100,150,500,1000,2000]\n",
    "\n",
    "    for x in values:\n",
    "\n",
    "        f = open(\"embeddings\" + \"/\" + character + str(x)+ \".txt\", \"w\")\n",
    "        for line in sentences[:x]:\n",
    "            f.write(line['sentence']+\"\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_calculator(line, character_lines, idf):\n",
    "\n",
    "    counts = 0\n",
    "\n",
    "    for sentence in character_lines:\n",
    "        if line in sentence:\n",
    "            counts += 1\n",
    "\n",
    "    tf = counts / len(character_lines)\n",
    "\n",
    "    tf_idf = tf * idf[line]\n",
    "\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = {}\n",
    "\n",
    "all_lines_set = [sentence.translate(str.maketrans('', '', string.punctuation)).lower() for sentence in all_lines]\n",
    "\n",
    "all_lines_set_no_stopwords = []\n",
    "\n",
    "for line in all_lines_set:\n",
    "    if line not in stopwords.words('english'):\n",
    "        all_lines_set_no_stopwords.append(line)\n",
    "\n",
    "\n",
    "for line in all_lines_set:\n",
    "    counts = 0\n",
    "    for sentence in all_lines_set:\n",
    "        if line in sentence:\n",
    "            counts += 1\n",
    "    \n",
    "    idf[line] = math.log(len(all_lines) / (1 + counts))\n",
    "\n",
    "#tf-idf for each character\n",
    "for character in characters:\n",
    "    character_lines = []\n",
    "    for line in train_set:\n",
    "        if character != 'others' and character in line['speakers']:\n",
    "            character_lines.append(line['transcript'])\n",
    "        elif character == 'others' and line['speakers'][0] not in characters:\n",
    "            character_lines.append(line['transcript'])\n",
    "    \n",
    "    tf_idfs = []\n",
    "\n",
    "    character_lines_processed = []\n",
    "\n",
    "    for line in character_lines:\n",
    "        line = line.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        if line not in stopwords.words('english'):\n",
    "            character_lines_processed.append(line)\n",
    "\n",
    "    for line in character_lines_processed:\n",
    "        tf_idfs.append(tf_idf_calculator(line, character_lines_processed, idf))\n",
    "\n",
    "    #associate values with sentences\n",
    "    sentences = []\n",
    "    for i in range(len(character_lines_processed)):\n",
    "        sentences.append({'sentence': character_lines_processed[i], 'value': tf_idfs[i]})\n",
    "    \n",
    "    #sort sentences by value\n",
    "    sentences = sorted(sentences, key = lambda i: i['value'], reverse=True)\n",
    "\n",
    "    sentences_only = [sentence['sentence'] for sentence in sentences]\n",
    "\n",
    "    #remove duplicates\n",
    "    sentences_only = list( dict.fromkeys(sentences_only) )\n",
    "\n",
    "    #change x for number of lines \n",
    "    values = [5,10,20,50,100,150,200,500,1000,2000,5000, 6000]\n",
    "\n",
    "    for x in values:\n",
    "\n",
    "        f = open(\"embeddings\" + \"/\" + character + str(x)+ \".txt\", \"w\")\n",
    "        for line in sentences_only[:x]:\n",
    "            f.write(line+\"\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_custom_idf(all_lines):\n",
    "    idf = {}\n",
    "    total_documents = len(all_lines)\n",
    "\n",
    "    term_document_count = {}\n",
    "    for line in all_lines:\n",
    "        counts = 0\n",
    "        for sentence in all_lines_set:\n",
    "            if line in sentence:\n",
    "                counts += 1\n",
    "        term_document_count[line] = counts\n",
    "\n",
    "    # Compute the IDF values with customization\n",
    "    for line, count in term_document_count.items():\n",
    "\n",
    "        idf[line] = math.log(total_documents / (count + 1))  # Adding 1 to avoid division by zero\n",
    "\n",
    "        # Customization: Lower the IDF for frequently occurring terms\n",
    "        if count > total_documents * 0.007:  # Adjust the threshold as needed\n",
    "            idf[line] *= 0.05  # Adjust the penalty factor as needed\n",
    "\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = {}\n",
    "\n",
    "all_lines_set = [sentence.translate(str.maketrans('', '', string.punctuation)).lower() for sentence in all_lines]\n",
    "\n",
    "all_lines_set_no_stopwords = []\n",
    "\n",
    "for line in all_lines_set:\n",
    "    if line not in stopwords.words('english'):\n",
    "        all_lines_set_no_stopwords.append(line)\n",
    "\n",
    "idf = calculate_custom_idf(all_lines_set_no_stopwords)\n",
    "\n",
    "\n",
    "#tf-idf for each character\n",
    "for character in characters:\n",
    "    character_lines = []\n",
    "    for line in train_set:\n",
    "        if character != 'others' and character in line['speakers']:\n",
    "            character_lines.append(line['transcript'])\n",
    "        elif character == 'others' and line['speakers'][0] not in characters:\n",
    "            character_lines.append(line['transcript'])\n",
    "    \n",
    "    tf_idfs = []\n",
    "\n",
    "    character_lines_processed = []\n",
    "\n",
    "    for line in character_lines:\n",
    "        line = line.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        if line not in stopwords.words('english'):\n",
    "            character_lines_processed.append(line)\n",
    "\n",
    "    for line in character_lines_processed:\n",
    "        tf_idfs.append(tf_idf_calculator(line, character_lines_processed, idf))\n",
    "\n",
    "\n",
    "    #associate values with sentences\n",
    "    sentences = []\n",
    "    for i in range(len(character_lines_processed)):\n",
    "        sentences.append({'sentence': character_lines_processed[i], 'value': tf_idfs[i]})\n",
    "    \n",
    "    #sort sentences by value\n",
    "    sentences = sorted(sentences, key = lambda i: i['value'], reverse=True)\n",
    "\n",
    "    sentences_only = [sentence['sentence'] for sentence in sentences]\n",
    "\n",
    "    #remove duplicates\n",
    "    sentences_only = list( dict.fromkeys(sentences_only) )\n",
    "\n",
    "    #change x for number of lines \n",
    "    values = [100,150,500,1000,2000]\n",
    "\n",
    "    for x in values:\n",
    "\n",
    "        f = open(\"embeddings\" + \"/\" + character + str(x)+ \".txt\", \"a\")\n",
    "        for line in sentences_only[:x]:\n",
    "            f.write(line+\"\\n\")\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
